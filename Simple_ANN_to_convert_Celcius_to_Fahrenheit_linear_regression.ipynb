{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple ANN to convert Celcius to Fahrenheit - linear regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noircir/TensorFlow-Examples/blob/master/Simple_ANN_to_convert_Celcius_to_Fahrenheit_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1UgBVV3zd-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "08ef3779-e191-4bdb-81a7-8cfb4bec8918"
      },
      "source": [
        "# T(f) = T(C) *9/5 + 32\n",
        "\n",
        "!pip install tensorflow-gpu==2.0.0.alpha0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0.alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 55kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.33.6)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.2.2)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.1.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 32.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.17.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0.alpha0) (41.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0.alpha0) (2.8.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UngpaIuK6bjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "9f267879-a711-4a4d-92aa-0415e2d6b83d"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAKaDCaN9SOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1cf04178-9cca-4593-f76d-5be7ce2244e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy9wBt_V91ZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Project 1 Celcius to Fahrenheit/Celsius-to-Fahrenheit.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW0DLdhO9744",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c343784a-32c3-4f14-ee64-116b4735620a"
      },
      "source": [
        "temp_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Celsius</th>\n",
              "      <th>Fahrenheit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-50</td>\n",
              "      <td>-58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-40</td>\n",
              "      <td>-40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-30</td>\n",
              "      <td>-22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-20</td>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-10</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Celsius  Fahrenheit\n",
              "0      -50       -58.0\n",
              "1      -40       -40.0\n",
              "2      -30       -22.0\n",
              "3      -20        -4.0\n",
              "4      -10        14.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMPFEc6F9_Dx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eadc26f6-718f-4669-93ac-a304a7dd7e3e"
      },
      "source": [
        "temp_df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPwLsnAf-BNZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "f59ff6b9-7ab7-474e-824c-081b1019c7cc"
      },
      "source": [
        "temp_df.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Celsius</th>\n",
              "      <th>Fahrenheit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>30.000000</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>35.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>22.780815</td>\n",
              "      <td>41.005466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-50.000000</td>\n",
              "      <td>-58.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-6.750000</td>\n",
              "      <td>19.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>32.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.750000</td>\n",
              "      <td>45.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>140.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Celsius  Fahrenheit\n",
              "count  30.000000   30.000000\n",
              "mean    2.000000   35.600000\n",
              "std    22.780815   41.005466\n",
              "min   -50.000000  -58.000000\n",
              "25%    -6.750000   19.850000\n",
              "50%     0.500000   32.900000\n",
              "75%     7.750000   45.950000\n",
              "max    60.000000  140.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA-4_NSk-JX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "584743fa-7406-4288-eb44-fbf6fbac0a21"
      },
      "source": [
        "temp_df.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30 entries, 0 to 29\n",
            "Data columns (total 2 columns):\n",
            "Celsius       30 non-null int64\n",
            "Fahrenheit    30 non-null float64\n",
            "dtypes: float64(1), int64(1)\n",
            "memory usage: 608.0 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu5O56VP-SRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "553cfd01-39ef-4cec-b63f-5a885ae1debb"
      },
      "source": [
        "sns.scatterplot(temp_df['Celsius'], temp_df['Fahrenheit'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb10b0e47b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnBzMzCzFycHMzFKcHMzMLMXJwczMUv4ffIyNt4IiK8UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_bVcoMy-pO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a2aa93c-1f2f-48e8-8653-f46a7c8423b7"
      },
      "source": [
        "X_train = temp_df['Celsius']\n",
        "y_train = temp_df['Fahrenheit']\n",
        "X_train.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSqzRz0k_OPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0066b730-c7fe-4ee3-c7ef-b22bd1c5f372"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfarGtdb_SjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a model with one layer (one weights, one bias)\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=1, input_shape=[1])) # one weight and one bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl6Zz7Lm_3P7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bc4ea361-46db-46ac-b382-b04f96e30ddb"
      },
      "source": [
        "# vizualize the model\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiguRlnw_8-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify an optimizer type with a learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.8), loss='mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k3u8FngBFGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef1093e5-ef13-4e98-945c-5a079534d61e"
      },
      "source": [
        "epochs_hist = model.fit(X_train, y_train, epochs=500)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "30/30 [==============================] - 1s 23ms/sample - loss: 1189.3352\n",
            "Epoch 2/500\n",
            "30/30 [==============================] - 0s 265us/sample - loss: 989.6683\n",
            "Epoch 3/500\n",
            "30/30 [==============================] - 0s 239us/sample - loss: 1051.5029\n",
            "Epoch 4/500\n",
            "30/30 [==============================] - 0s 158us/sample - loss: 938.5480\n",
            "Epoch 5/500\n",
            "30/30 [==============================] - 0s 185us/sample - loss: 825.9216\n",
            "Epoch 6/500\n",
            "30/30 [==============================] - 0s 201us/sample - loss: 803.1168\n",
            "Epoch 7/500\n",
            "30/30 [==============================] - 0s 186us/sample - loss: 800.5528\n",
            "Epoch 8/500\n",
            "30/30 [==============================] - 0s 185us/sample - loss: 746.5761\n",
            "Epoch 9/500\n",
            "30/30 [==============================] - 0s 233us/sample - loss: 667.4161\n",
            "Epoch 10/500\n",
            "30/30 [==============================] - 0s 163us/sample - loss: 613.6897\n",
            "Epoch 11/500\n",
            "30/30 [==============================] - 0s 125us/sample - loss: 594.5869\n",
            "Epoch 12/500\n",
            "30/30 [==============================] - 0s 133us/sample - loss: 576.4293\n",
            "Epoch 13/500\n",
            "30/30 [==============================] - 0s 160us/sample - loss: 534.3516\n",
            "Epoch 14/500\n",
            "30/30 [==============================] - 0s 125us/sample - loss: 480.1646\n",
            "Epoch 15/500\n",
            "30/30 [==============================] - 0s 151us/sample - loss: 438.6563\n",
            "Epoch 16/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 416.9173\n",
            "Epoch 17/500\n",
            "30/30 [==============================] - 0s 152us/sample - loss: 399.2217\n",
            "Epoch 18/500\n",
            "30/30 [==============================] - 0s 134us/sample - loss: 369.7821\n",
            "Epoch 19/500\n",
            "30/30 [==============================] - 0s 123us/sample - loss: 331.6226\n",
            "Epoch 20/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 299.0575\n",
            "Epoch 21/500\n",
            "30/30 [==============================] - 0s 195us/sample - loss: 279.0104\n",
            "Epoch 22/500\n",
            "30/30 [==============================] - 0s 117us/sample - loss: 264.0049\n",
            "Epoch 23/500\n",
            "30/30 [==============================] - 0s 151us/sample - loss: 243.3907\n",
            "Epoch 24/500\n",
            "30/30 [==============================] - 0s 124us/sample - loss: 216.8197\n",
            "Epoch 25/500\n",
            "30/30 [==============================] - 0s 112us/sample - loss: 192.7688\n",
            "Epoch 26/500\n",
            "30/30 [==============================] - 0s 136us/sample - loss: 176.7738\n",
            "Epoch 27/500\n",
            "30/30 [==============================] - 0s 220us/sample - loss: 165.0597\n",
            "Epoch 28/500\n",
            "30/30 [==============================] - 0s 143us/sample - loss: 150.5979\n",
            "Epoch 29/500\n",
            "30/30 [==============================] - 0s 123us/sample - loss: 132.4523\n",
            "Epoch 30/500\n",
            "30/30 [==============================] - 0s 128us/sample - loss: 115.9043\n",
            "Epoch 31/500\n",
            "30/30 [==============================] - 0s 191us/sample - loss: 104.6963\n",
            "Epoch 32/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 96.3992\n",
            "Epoch 33/500\n",
            "30/30 [==============================] - 0s 125us/sample - loss: 86.4480\n",
            "Epoch 34/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 74.4340\n",
            "Epoch 35/500\n",
            "30/30 [==============================] - 0s 119us/sample - loss: 63.9227\n",
            "Epoch 36/500\n",
            "30/30 [==============================] - 0s 137us/sample - loss: 57.0143\n",
            "Epoch 37/500\n",
            "30/30 [==============================] - 0s 131us/sample - loss: 51.6694\n",
            "Epoch 38/500\n",
            "30/30 [==============================] - 0s 138us/sample - loss: 45.0626\n",
            "Epoch 39/500\n",
            "30/30 [==============================] - 0s 143us/sample - loss: 37.5416\n",
            "Epoch 40/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 31.5814\n",
            "Epoch 41/500\n",
            "30/30 [==============================] - 0s 157us/sample - loss: 27.9241\n",
            "Epoch 42/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 24.7330\n",
            "Epoch 43/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 20.5590\n",
            "Epoch 44/500\n",
            "30/30 [==============================] - 0s 147us/sample - loss: 16.3113\n",
            "Epoch 45/500\n",
            "30/30 [==============================] - 0s 152us/sample - loss: 13.5055\n",
            "Epoch 46/500\n",
            "30/30 [==============================] - 0s 120us/sample - loss: 11.8907\n",
            "Epoch 47/500\n",
            "30/30 [==============================] - 0s 121us/sample - loss: 10.0419\n",
            "Epoch 48/500\n",
            "30/30 [==============================] - 0s 191us/sample - loss: 7.6230\n",
            "Epoch 49/500\n",
            "30/30 [==============================] - 0s 149us/sample - loss: 5.6692\n",
            "Epoch 50/500\n",
            "30/30 [==============================] - 0s 149us/sample - loss: 4.7506\n",
            "Epoch 51/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 4.1281\n",
            "Epoch 52/500\n",
            "30/30 [==============================] - 0s 159us/sample - loss: 3.0600\n",
            "Epoch 53/500\n",
            "30/30 [==============================] - 0s 115us/sample - loss: 1.9170\n",
            "Epoch 54/500\n",
            "30/30 [==============================] - 0s 134us/sample - loss: 1.3844\n",
            "Epoch 55/500\n",
            "30/30 [==============================] - 0s 170us/sample - loss: 1.2947\n",
            "Epoch 56/500\n",
            "30/30 [==============================] - 0s 163us/sample - loss: 0.9993\n",
            "Epoch 57/500\n",
            "30/30 [==============================] - 0s 168us/sample - loss: 0.4580\n",
            "Epoch 58/500\n",
            "30/30 [==============================] - 0s 183us/sample - loss: 0.1785\n",
            "Epoch 59/500\n",
            "30/30 [==============================] - 0s 413us/sample - loss: 0.2766\n",
            "Epoch 60/500\n",
            "30/30 [==============================] - 0s 377us/sample - loss: 0.3282\n",
            "Epoch 61/500\n",
            "30/30 [==============================] - 0s 223us/sample - loss: 0.1391\n",
            "Epoch 62/500\n",
            "30/30 [==============================] - 0s 209us/sample - loss: 0.0127\n",
            "Epoch 63/500\n",
            "30/30 [==============================] - 0s 231us/sample - loss: 0.1457\n",
            "Epoch 64/500\n",
            "30/30 [==============================] - 0s 235us/sample - loss: 0.3005\n",
            "Epoch 65/500\n",
            "30/30 [==============================] - 0s 262us/sample - loss: 0.2694\n",
            "Epoch 66/500\n",
            "30/30 [==============================] - 0s 248us/sample - loss: 0.2151\n",
            "Epoch 67/500\n",
            "30/30 [==============================] - 0s 250us/sample - loss: 0.3214\n",
            "Epoch 68/500\n",
            "30/30 [==============================] - 0s 216us/sample - loss: 0.4655\n",
            "Epoch 69/500\n",
            "30/30 [==============================] - 0s 227us/sample - loss: 0.4774\n",
            "Epoch 70/500\n",
            "30/30 [==============================] - 0s 197us/sample - loss: 0.4421\n",
            "Epoch 71/500\n",
            "30/30 [==============================] - 0s 227us/sample - loss: 0.5040\n",
            "Epoch 72/500\n",
            "30/30 [==============================] - 0s 221us/sample - loss: 0.5987\n",
            "Epoch 73/500\n",
            "30/30 [==============================] - 0s 229us/sample - loss: 0.6018\n",
            "Epoch 74/500\n",
            "30/30 [==============================] - 0s 247us/sample - loss: 0.5615\n",
            "Epoch 75/500\n",
            "30/30 [==============================] - 0s 501us/sample - loss: 0.5826\n",
            "Epoch 76/500\n",
            "30/30 [==============================] - 0s 267us/sample - loss: 0.6268\n",
            "Epoch 77/500\n",
            "30/30 [==============================] - 0s 202us/sample - loss: 0.6077\n",
            "Epoch 78/500\n",
            "30/30 [==============================] - 0s 210us/sample - loss: 0.5585\n",
            "Epoch 79/500\n",
            "30/30 [==============================] - 0s 243us/sample - loss: 0.5517\n",
            "Epoch 80/500\n",
            "30/30 [==============================] - 0s 191us/sample - loss: 0.5590\n",
            "Epoch 81/500\n",
            "30/30 [==============================] - 0s 525us/sample - loss: 0.5227\n",
            "Epoch 82/500\n",
            "30/30 [==============================] - 0s 318us/sample - loss: 0.4705\n",
            "Epoch 83/500\n",
            "30/30 [==============================] - 0s 151us/sample - loss: 0.4500\n",
            "Epoch 84/500\n",
            "30/30 [==============================] - 0s 184us/sample - loss: 0.4364\n",
            "Epoch 85/500\n",
            "30/30 [==============================] - 0s 103us/sample - loss: 0.3935\n",
            "Epoch 86/500\n",
            "30/30 [==============================] - 0s 161us/sample - loss: 0.3461\n",
            "Epoch 87/500\n",
            "30/30 [==============================] - 0s 191us/sample - loss: 0.3229\n",
            "Epoch 88/500\n",
            "30/30 [==============================] - 0s 298us/sample - loss: 0.3014\n",
            "Epoch 89/500\n",
            "30/30 [==============================] - 0s 149us/sample - loss: 0.2612\n",
            "Epoch 90/500\n",
            "30/30 [==============================] - 0s 146us/sample - loss: 0.2242\n",
            "Epoch 91/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 0.2049\n",
            "Epoch 92/500\n",
            "30/30 [==============================] - 0s 104us/sample - loss: 0.1836\n",
            "Epoch 93/500\n",
            "30/30 [==============================] - 0s 367us/sample - loss: 0.1516\n",
            "Epoch 94/500\n",
            "30/30 [==============================] - 0s 254us/sample - loss: 0.1270\n",
            "Epoch 95/500\n",
            "30/30 [==============================] - 0s 299us/sample - loss: 0.1139\n",
            "Epoch 96/500\n",
            "30/30 [==============================] - 0s 288us/sample - loss: 0.0967\n",
            "Epoch 97/500\n",
            "30/30 [==============================] - 0s 243us/sample - loss: 0.0749\n",
            "Epoch 98/500\n",
            "30/30 [==============================] - 0s 293us/sample - loss: 0.0614\n",
            "Epoch 99/500\n",
            "30/30 [==============================] - 0s 192us/sample - loss: 0.0538\n",
            "Epoch 100/500\n",
            "30/30 [==============================] - 0s 164us/sample - loss: 0.0419\n",
            "Epoch 101/500\n",
            "30/30 [==============================] - 0s 200us/sample - loss: 0.0295\n",
            "Epoch 102/500\n",
            "30/30 [==============================] - 0s 197us/sample - loss: 0.0242\n",
            "Epoch 103/500\n",
            "30/30 [==============================] - 0s 203us/sample - loss: 0.0203\n",
            "Epoch 104/500\n",
            "30/30 [==============================] - 0s 191us/sample - loss: 0.0131\n",
            "Epoch 105/500\n",
            "30/30 [==============================] - 0s 184us/sample - loss: 0.0080\n",
            "Epoch 106/500\n",
            "30/30 [==============================] - 0s 198us/sample - loss: 0.0072\n",
            "Epoch 107/500\n",
            "30/30 [==============================] - 0s 209us/sample - loss: 0.0054\n",
            "Epoch 108/500\n",
            "30/30 [==============================] - 0s 231us/sample - loss: 0.0019\n",
            "Epoch 109/500\n",
            "30/30 [==============================] - 0s 189us/sample - loss: 0.0011\n",
            "Epoch 110/500\n",
            "30/30 [==============================] - 0s 192us/sample - loss: 0.0020\n",
            "Epoch 111/500\n",
            "30/30 [==============================] - 0s 273us/sample - loss: 0.0011\n",
            "Epoch 112/500\n",
            "30/30 [==============================] - 0s 211us/sample - loss: 1.0602e-04\n",
            "Epoch 113/500\n",
            "30/30 [==============================] - 0s 242us/sample - loss: 0.0012\n",
            "Epoch 114/500\n",
            "30/30 [==============================] - 0s 254us/sample - loss: 0.0021\n",
            "Epoch 115/500\n",
            "30/30 [==============================] - 0s 219us/sample - loss: 0.0016\n",
            "Epoch 116/500\n",
            "30/30 [==============================] - 0s 247us/sample - loss: 0.0019\n",
            "Epoch 117/500\n",
            "30/30 [==============================] - 0s 224us/sample - loss: 0.0032\n",
            "Epoch 118/500\n",
            "30/30 [==============================] - 0s 247us/sample - loss: 0.0034\n",
            "Epoch 119/500\n",
            "30/30 [==============================] - 0s 279us/sample - loss: 0.0032\n",
            "Epoch 120/500\n",
            "30/30 [==============================] - 0s 206us/sample - loss: 0.0039\n",
            "Epoch 121/500\n",
            "30/30 [==============================] - 0s 235us/sample - loss: 0.0045\n",
            "Epoch 122/500\n",
            "30/30 [==============================] - 0s 220us/sample - loss: 0.0042\n",
            "Epoch 123/500\n",
            "30/30 [==============================] - 0s 214us/sample - loss: 0.0043\n",
            "Epoch 124/500\n",
            "30/30 [==============================] - 0s 320us/sample - loss: 0.0047\n",
            "Epoch 125/500\n",
            "30/30 [==============================] - 0s 216us/sample - loss: 0.0045\n",
            "Epoch 126/500\n",
            "30/30 [==============================] - 0s 227us/sample - loss: 0.0042\n",
            "Epoch 127/500\n",
            "30/30 [==============================] - 0s 246us/sample - loss: 0.0042\n",
            "Epoch 128/500\n",
            "30/30 [==============================] - 0s 215us/sample - loss: 0.0042\n",
            "Epoch 129/500\n",
            "30/30 [==============================] - 0s 216us/sample - loss: 0.0037\n",
            "Epoch 130/500\n",
            "30/30 [==============================] - 0s 294us/sample - loss: 0.0035\n",
            "Epoch 131/500\n",
            "30/30 [==============================] - 0s 247us/sample - loss: 0.0034\n",
            "Epoch 132/500\n",
            "30/30 [==============================] - 0s 272us/sample - loss: 0.0030\n",
            "Epoch 133/500\n",
            "30/30 [==============================] - 0s 241us/sample - loss: 0.0026\n",
            "Epoch 134/500\n",
            "30/30 [==============================] - 0s 221us/sample - loss: 0.0025\n",
            "Epoch 135/500\n",
            "30/30 [==============================] - 0s 214us/sample - loss: 0.0022\n",
            "Epoch 136/500\n",
            "30/30 [==============================] - 0s 261us/sample - loss: 0.0018\n",
            "Epoch 137/500\n",
            "30/30 [==============================] - 0s 158us/sample - loss: 0.0016\n",
            "Epoch 138/500\n",
            "30/30 [==============================] - 0s 181us/sample - loss: 0.0015\n",
            "Epoch 139/500\n",
            "30/30 [==============================] - 0s 179us/sample - loss: 0.0012\n",
            "Epoch 140/500\n",
            "30/30 [==============================] - 0s 97us/sample - loss: 9.4387e-04\n",
            "Epoch 141/500\n",
            "30/30 [==============================] - 0s 208us/sample - loss: 8.3607e-04\n",
            "Epoch 142/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 6.6290e-04\n",
            "Epoch 143/500\n",
            "30/30 [==============================] - 0s 214us/sample - loss: 4.8238e-04\n",
            "Epoch 144/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 4.0778e-04\n",
            "Epoch 145/500\n",
            "30/30 [==============================] - 0s 131us/sample - loss: 3.2612e-04\n",
            "Epoch 146/500\n",
            "30/30 [==============================] - 0s 119us/sample - loss: 2.0570e-04\n",
            "Epoch 147/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 1.5384e-04\n",
            "Epoch 148/500\n",
            "30/30 [==============================] - 0s 124us/sample - loss: 1.3082e-04\n",
            "Epoch 149/500\n",
            "30/30 [==============================] - 0s 430us/sample - loss: 6.7873e-05\n",
            "Epoch 150/500\n",
            "30/30 [==============================] - 0s 228us/sample - loss: 3.4105e-05\n",
            "Epoch 151/500\n",
            "30/30 [==============================] - 0s 271us/sample - loss: 4.0463e-05\n",
            "Epoch 152/500\n",
            "30/30 [==============================] - 0s 274us/sample - loss: 1.9852e-05\n",
            "Epoch 153/500\n",
            "30/30 [==============================] - 0s 259us/sample - loss: 4.2493e-07\n",
            "Epoch 154/500\n",
            "30/30 [==============================] - 0s 301us/sample - loss: 1.6287e-05\n",
            "Epoch 155/500\n",
            "30/30 [==============================] - 0s 223us/sample - loss: 1.9946e-05\n",
            "Epoch 156/500\n",
            "30/30 [==============================] - 0s 151us/sample - loss: 1.0505e-05\n",
            "Epoch 157/500\n",
            "30/30 [==============================] - 0s 155us/sample - loss: 2.4887e-05\n",
            "Epoch 158/500\n",
            "30/30 [==============================] - 0s 118us/sample - loss: 3.8041e-05\n",
            "Epoch 159/500\n",
            "30/30 [==============================] - 0s 156us/sample - loss: 3.4186e-05\n",
            "Epoch 160/500\n",
            "30/30 [==============================] - 0s 361us/sample - loss: 4.2682e-05\n",
            "Epoch 161/500\n",
            "30/30 [==============================] - 0s 321us/sample - loss: 5.5919e-05\n",
            "Epoch 162/500\n",
            "30/30 [==============================] - 0s 263us/sample - loss: 5.4098e-05\n",
            "Epoch 163/500\n",
            "30/30 [==============================] - 0s 269us/sample - loss: 5.6176e-05\n",
            "Epoch 164/500\n",
            "30/30 [==============================] - 0s 265us/sample - loss: 6.5131e-05\n",
            "Epoch 165/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 6.3224e-05\n",
            "Epoch 166/500\n",
            "30/30 [==============================] - 0s 431us/sample - loss: 6.0244e-05\n",
            "Epoch 167/500\n",
            "30/30 [==============================] - 0s 311us/sample - loss: 6.4077e-05\n",
            "Epoch 168/500\n",
            "30/30 [==============================] - 0s 301us/sample - loss: 6.1395e-05\n",
            "Epoch 169/500\n",
            "30/30 [==============================] - 0s 212us/sample - loss: 5.5465e-05\n",
            "Epoch 170/500\n",
            "30/30 [==============================] - 0s 224us/sample - loss: 5.5159e-05\n",
            "Epoch 171/500\n",
            "30/30 [==============================] - 0s 205us/sample - loss: 5.1808e-05\n",
            "Epoch 172/500\n",
            "30/30 [==============================] - 0s 191us/sample - loss: 4.4866e-05\n",
            "Epoch 173/500\n",
            "30/30 [==============================] - 0s 201us/sample - loss: 4.2204e-05\n",
            "Epoch 174/500\n",
            "30/30 [==============================] - 0s 212us/sample - loss: 3.8796e-05\n",
            "Epoch 175/500\n",
            "30/30 [==============================] - 0s 196us/sample - loss: 3.2224e-05\n",
            "Epoch 176/500\n",
            "30/30 [==============================] - 0s 230us/sample - loss: 2.8703e-05\n",
            "Epoch 177/500\n",
            "30/30 [==============================] - 0s 203us/sample - loss: 2.5777e-05\n",
            "Epoch 178/500\n",
            "30/30 [==============================] - 0s 202us/sample - loss: 2.0459e-05\n",
            "Epoch 179/500\n",
            "30/30 [==============================] - 0s 205us/sample - loss: 1.7165e-05\n",
            "Epoch 180/500\n",
            "30/30 [==============================] - 0s 235us/sample - loss: 1.5066e-05\n",
            "Epoch 181/500\n",
            "30/30 [==============================] - 0s 276us/sample - loss: 1.1258e-05\n",
            "Epoch 182/500\n",
            "30/30 [==============================] - 0s 263us/sample - loss: 8.7433e-06\n",
            "Epoch 183/500\n",
            "30/30 [==============================] - 0s 178us/sample - loss: 7.5268e-06\n",
            "Epoch 184/500\n",
            "30/30 [==============================] - 0s 171us/sample - loss: 5.1294e-06\n",
            "Epoch 185/500\n",
            "30/30 [==============================] - 0s 168us/sample - loss: 3.4891e-06\n",
            "Epoch 186/500\n",
            "30/30 [==============================] - 0s 174us/sample - loss: 3.0320e-06\n",
            "Epoch 187/500\n",
            "30/30 [==============================] - 0s 168us/sample - loss: 1.7558e-06\n",
            "Epoch 188/500\n",
            "30/30 [==============================] - 0s 176us/sample - loss: 8.7447e-07\n",
            "Epoch 189/500\n",
            "30/30 [==============================] - 0s 192us/sample - loss: 9.3082e-07\n",
            "Epoch 190/500\n",
            "30/30 [==============================] - 0s 213us/sample - loss: 4.1328e-07\n",
            "Epoch 191/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 4.5883e-08\n",
            "Epoch 192/500\n",
            "30/30 [==============================] - 0s 253us/sample - loss: 3.7554e-07\n",
            "Epoch 193/500\n",
            "30/30 [==============================] - 0s 247us/sample - loss: 2.7516e-07\n",
            "Epoch 194/500\n",
            "30/30 [==============================] - 0s 252us/sample - loss: 1.7806e-07\n",
            "Epoch 195/500\n",
            "30/30 [==============================] - 0s 202us/sample - loss: 5.7621e-07\n",
            "Epoch 196/500\n",
            "30/30 [==============================] - 0s 261us/sample - loss: 6.3851e-07\n",
            "Epoch 197/500\n",
            "30/30 [==============================] - 0s 152us/sample - loss: 6.3419e-07\n",
            "Epoch 198/500\n",
            "30/30 [==============================] - 0s 165us/sample - loss: 9.7376e-07\n",
            "Epoch 199/500\n",
            "30/30 [==============================] - 0s 178us/sample - loss: 1.0481e-06\n",
            "Epoch 200/500\n",
            "30/30 [==============================] - 0s 246us/sample - loss: 1.0359e-06\n",
            "Epoch 201/500\n",
            "30/30 [==============================] - 0s 259us/sample - loss: 1.2525e-06\n",
            "Epoch 202/500\n",
            "30/30 [==============================] - 0s 161us/sample - loss: 1.2725e-06\n",
            "Epoch 203/500\n",
            "30/30 [==============================] - 0s 197us/sample - loss: 1.2073e-06\n",
            "Epoch 204/500\n",
            "30/30 [==============================] - 0s 250us/sample - loss: 1.3103e-06\n",
            "Epoch 205/500\n",
            "30/30 [==============================] - 0s 254us/sample - loss: 1.2602e-06\n",
            "Epoch 206/500\n",
            "30/30 [==============================] - 0s 190us/sample - loss: 1.1493e-06\n",
            "Epoch 207/500\n",
            "30/30 [==============================] - 0s 282us/sample - loss: 1.1628e-06\n",
            "Epoch 208/500\n",
            "30/30 [==============================] - 0s 215us/sample - loss: 1.0713e-06\n",
            "Epoch 209/500\n",
            "30/30 [==============================] - 0s 188us/sample - loss: 9.4018e-07\n",
            "Epoch 210/500\n",
            "30/30 [==============================] - 0s 178us/sample - loss: 9.0442e-07\n",
            "Epoch 211/500\n",
            "30/30 [==============================] - 0s 239us/sample - loss: 7.9211e-07\n",
            "Epoch 212/500\n",
            "30/30 [==============================] - 0s 119us/sample - loss: 6.6513e-07\n",
            "Epoch 213/500\n",
            "30/30 [==============================] - 0s 107us/sample - loss: 6.1581e-07\n",
            "Epoch 214/500\n",
            "30/30 [==============================] - 0s 168us/sample - loss: 5.1214e-07\n",
            "Epoch 215/500\n",
            "30/30 [==============================] - 0s 189us/sample - loss: 4.0917e-07\n",
            "Epoch 216/500\n",
            "30/30 [==============================] - 0s 172us/sample - loss: 3.6532e-07\n",
            "Epoch 217/500\n",
            "30/30 [==============================] - 0s 167us/sample - loss: 2.8161e-07\n",
            "Epoch 218/500\n",
            "30/30 [==============================] - 0s 342us/sample - loss: 2.1078e-07\n",
            "Epoch 219/500\n",
            "30/30 [==============================] - 0s 119us/sample - loss: 1.8154e-07\n",
            "Epoch 220/500\n",
            "30/30 [==============================] - 0s 133us/sample - loss: 1.2449e-07\n",
            "Epoch 221/500\n",
            "30/30 [==============================] - 0s 108us/sample - loss: 8.4008e-08\n",
            "Epoch 222/500\n",
            "30/30 [==============================] - 0s 138us/sample - loss: 7.1625e-08\n",
            "Epoch 223/500\n",
            "30/30 [==============================] - 0s 147us/sample - loss: 3.8758e-08\n",
            "Epoch 224/500\n",
            "30/30 [==============================] - 0s 143us/sample - loss: 2.1290e-08\n",
            "Epoch 225/500\n",
            "30/30 [==============================] - 0s 156us/sample - loss: 2.1823e-08\n",
            "Epoch 226/500\n",
            "30/30 [==============================] - 0s 237us/sample - loss: 5.5781e-09\n",
            "Epoch 227/500\n",
            "30/30 [==============================] - 0s 523us/sample - loss: 3.4863e-09\n",
            "Epoch 228/500\n",
            "30/30 [==============================] - 0s 272us/sample - loss: 1.0457e-08\n",
            "Epoch 229/500\n",
            "30/30 [==============================] - 0s 255us/sample - loss: 3.7779e-09\n",
            "Epoch 230/500\n",
            "30/30 [==============================] - 0s 298us/sample - loss: 9.1081e-09\n",
            "Epoch 231/500\n",
            "30/30 [==============================] - 0s 270us/sample - loss: 1.6856e-08\n",
            "Epoch 232/500\n",
            "30/30 [==============================] - 0s 158us/sample - loss: 1.4246e-08\n",
            "Epoch 233/500\n",
            "30/30 [==============================] - 0s 201us/sample - loss: 2.1215e-08\n",
            "Epoch 234/500\n",
            "30/30 [==============================] - 0s 124us/sample - loss: 2.6539e-08\n",
            "Epoch 235/500\n",
            "30/30 [==============================] - 0s 161us/sample - loss: 2.5602e-08\n",
            "Epoch 236/500\n",
            "30/30 [==============================] - 0s 123us/sample - loss: 3.1082e-08\n",
            "Epoch 237/500\n",
            "30/30 [==============================] - 0s 125us/sample - loss: 3.2217e-08\n",
            "Epoch 238/500\n",
            "30/30 [==============================] - 0s 274us/sample - loss: 3.0528e-08\n",
            "Epoch 239/500\n",
            "30/30 [==============================] - 0s 278us/sample - loss: 3.3337e-08\n",
            "Epoch 240/500\n",
            "30/30 [==============================] - 0s 222us/sample - loss: 3.2387e-08\n",
            "Epoch 241/500\n",
            "30/30 [==============================] - 0s 238us/sample - loss: 2.9393e-08\n",
            "Epoch 242/500\n",
            "30/30 [==============================] - 0s 229us/sample - loss: 3.0161e-08\n",
            "Epoch 243/500\n",
            "30/30 [==============================] - 0s 158us/sample - loss: 2.7860e-08\n",
            "Epoch 244/500\n",
            "30/30 [==============================] - 0s 156us/sample - loss: 2.4479e-08\n",
            "Epoch 245/500\n",
            "30/30 [==============================] - 0s 183us/sample - loss: 2.3733e-08\n",
            "Epoch 246/500\n",
            "30/30 [==============================] - 0s 126us/sample - loss: 2.0334e-08\n",
            "Epoch 247/500\n",
            "30/30 [==============================] - 0s 179us/sample - loss: 1.7992e-08\n",
            "Epoch 248/500\n",
            "30/30 [==============================] - 0s 211us/sample - loss: 1.6076e-08\n",
            "Epoch 249/500\n",
            "30/30 [==============================] - 0s 204us/sample - loss: 1.2293e-08\n",
            "Epoch 250/500\n",
            "30/30 [==============================] - 0s 206us/sample - loss: 1.0117e-08\n",
            "Epoch 251/500\n",
            "30/30 [==============================] - 0s 227us/sample - loss: 8.5647e-09\n",
            "Epoch 252/500\n",
            "30/30 [==============================] - 0s 237us/sample - loss: 5.8166e-09\n",
            "Epoch 253/500\n",
            "30/30 [==============================] - 0s 237us/sample - loss: 4.7973e-09\n",
            "Epoch 254/500\n",
            "30/30 [==============================] - 0s 239us/sample - loss: 3.5073e-09\n",
            "Epoch 255/500\n",
            "30/30 [==============================] - 0s 233us/sample - loss: 1.7203e-09\n",
            "Epoch 256/500\n",
            "30/30 [==============================] - 0s 244us/sample - loss: 1.8383e-09\n",
            "Epoch 257/500\n",
            "30/30 [==============================] - 0s 232us/sample - loss: 1.1134e-09\n",
            "Epoch 258/500\n",
            "30/30 [==============================] - 0s 235us/sample - loss: 4.1803e-10\n",
            "Epoch 259/500\n",
            "30/30 [==============================] - 0s 248us/sample - loss: 7.3721e-10\n",
            "Epoch 260/500\n",
            "30/30 [==============================] - 0s 149us/sample - loss: 1.4312e-10\n",
            "Epoch 261/500\n",
            "30/30 [==============================] - 0s 252us/sample - loss: 1.6435e-10\n",
            "Epoch 262/500\n",
            "30/30 [==============================] - 0s 229us/sample - loss: 4.5672e-10\n",
            "Epoch 263/500\n",
            "30/30 [==============================] - 0s 212us/sample - loss: 1.9296e-10\n",
            "Epoch 264/500\n",
            "30/30 [==============================] - 0s 218us/sample - loss: 4.4447e-10\n",
            "Epoch 265/500\n",
            "30/30 [==============================] - 0s 252us/sample - loss: 6.0478e-10\n",
            "Epoch 266/500\n",
            "30/30 [==============================] - 0s 221us/sample - loss: 5.9047e-10\n",
            "Epoch 267/500\n",
            "30/30 [==============================] - 0s 210us/sample - loss: 8.8467e-10\n",
            "Epoch 268/500\n",
            "30/30 [==============================] - 0s 256us/sample - loss: 9.4700e-10\n",
            "Epoch 269/500\n",
            "30/30 [==============================] - 0s 192us/sample - loss: 9.3390e-10\n",
            "Epoch 270/500\n",
            "30/30 [==============================] - 0s 155us/sample - loss: 1.1875e-09\n",
            "Epoch 271/500\n",
            "30/30 [==============================] - 0s 165us/sample - loss: 1.0890e-09\n",
            "Epoch 272/500\n",
            "30/30 [==============================] - 0s 135us/sample - loss: 1.0720e-09\n",
            "Epoch 273/500\n",
            "30/30 [==============================] - 0s 132us/sample - loss: 1.1801e-09\n",
            "Epoch 274/500\n",
            "30/30 [==============================] - 0s 149us/sample - loss: 1.0542e-09\n",
            "Epoch 275/500\n",
            "30/30 [==============================] - 0s 192us/sample - loss: 1.0890e-09\n",
            "Epoch 276/500\n",
            "30/30 [==============================] - 0s 241us/sample - loss: 1.0185e-09\n",
            "Epoch 277/500\n",
            "30/30 [==============================] - 0s 218us/sample - loss: 8.2258e-10\n",
            "Epoch 278/500\n",
            "30/30 [==============================] - 0s 225us/sample - loss: 7.5188e-10\n",
            "Epoch 279/500\n",
            "30/30 [==============================] - 0s 143us/sample - loss: 6.4759e-10\n",
            "Epoch 280/500\n",
            "30/30 [==============================] - 0s 281us/sample - loss: 5.1529e-10\n",
            "Epoch 281/500\n",
            "30/30 [==============================] - 0s 290us/sample - loss: 5.1626e-10\n",
            "Epoch 282/500\n",
            "30/30 [==============================] - 0s 178us/sample - loss: 4.1258e-10\n",
            "Epoch 283/500\n",
            "30/30 [==============================] - 0s 349us/sample - loss: 3.2175e-10\n",
            "Epoch 284/500\n",
            "30/30 [==============================] - 0s 230us/sample - loss: 2.9762e-10\n",
            "Epoch 285/500\n",
            "30/30 [==============================] - 0s 285us/sample - loss: 1.9296e-10\n",
            "Epoch 286/500\n",
            "30/30 [==============================] - 0s 217us/sample - loss: 1.3949e-10\n",
            "Epoch 287/500\n",
            "30/30 [==============================] - 0s 154us/sample - loss: 1.5319e-10\n",
            "Epoch 288/500\n",
            "30/30 [==============================] - 0s 191us/sample - loss: 5.7389e-11\n",
            "Epoch 289/500\n",
            "30/30 [==============================] - 0s 234us/sample - loss: 5.6662e-11\n",
            "Epoch 290/500\n",
            "30/30 [==============================] - 0s 268us/sample - loss: 3.4834e-11\n",
            "Epoch 291/500\n",
            "30/30 [==============================] - 0s 237us/sample - loss: 3.7896e-12\n",
            "Epoch 292/500\n",
            "30/30 [==============================] - 0s 258us/sample - loss: 5.0356e-11\n",
            "Epoch 293/500\n",
            "30/30 [==============================] - 0s 264us/sample - loss: 6.3665e-13\n",
            "Epoch 294/500\n",
            "30/30 [==============================] - 0s 264us/sample - loss: 6.3665e-13\n",
            "Epoch 295/500\n",
            "30/30 [==============================] - 0s 249us/sample - loss: 2.1494e-11\n",
            "Epoch 296/500\n",
            "30/30 [==============================] - 0s 176us/sample - loss: 6.3665e-13\n",
            "Epoch 297/500\n",
            "30/30 [==============================] - 0s 224us/sample - loss: 6.3665e-13\n",
            "Epoch 298/500\n",
            "30/30 [==============================] - 0s 116us/sample - loss: 1.0217e-11\n",
            "Epoch 299/500\n",
            "30/30 [==============================] - 0s 142us/sample - loss: 1.0217e-11\n",
            "Epoch 300/500\n",
            "30/30 [==============================] - 0s 135us/sample - loss: 6.3665e-13\n",
            "Epoch 301/500\n",
            "30/30 [==============================] - 0s 125us/sample - loss: 2.1494e-11\n",
            "Epoch 302/500\n",
            "30/30 [==============================] - 0s 123us/sample - loss: 6.3665e-13\n",
            "Epoch 303/500\n",
            "30/30 [==============================] - 0s 141us/sample - loss: 6.3665e-13\n",
            "Epoch 304/500\n",
            "30/30 [==============================] - 0s 127us/sample - loss: 1.0217e-11\n",
            "Epoch 305/500\n",
            "30/30 [==============================] - 0s 124us/sample - loss: 6.3665e-13\n",
            "Epoch 306/500\n",
            "30/30 [==============================] - 0s 136us/sample - loss: 6.3665e-13\n",
            "Epoch 307/500\n",
            "30/30 [==============================] - 0s 142us/sample - loss: 6.3665e-13\n",
            "Epoch 308/500\n",
            "30/30 [==============================] - 0s 235us/sample - loss: 6.3665e-13\n",
            "Epoch 309/500\n",
            "30/30 [==============================] - 0s 180us/sample - loss: 6.3665e-13\n",
            "Epoch 310/500\n",
            "30/30 [==============================] - 0s 107us/sample - loss: 6.3665e-13\n",
            "Epoch 311/500\n",
            "30/30 [==============================] - 0s 122us/sample - loss: 6.3665e-13\n",
            "Epoch 312/500\n",
            "30/30 [==============================] - 0s 104us/sample - loss: 6.3665e-13\n",
            "Epoch 313/500\n",
            "30/30 [==============================] - 0s 138us/sample - loss: 6.3665e-13\n",
            "Epoch 314/500\n",
            "30/30 [==============================] - 0s 127us/sample - loss: 6.3665e-13\n",
            "Epoch 315/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 6.3665e-13\n",
            "Epoch 316/500\n",
            "30/30 [==============================] - 0s 431us/sample - loss: 6.3665e-13\n",
            "Epoch 317/500\n",
            "30/30 [==============================] - 0s 393us/sample - loss: 6.3665e-13\n",
            "Epoch 318/500\n",
            "30/30 [==============================] - 0s 430us/sample - loss: 6.3665e-13\n",
            "Epoch 319/500\n",
            "30/30 [==============================] - 0s 257us/sample - loss: 6.3665e-13\n",
            "Epoch 320/500\n",
            "30/30 [==============================] - 0s 269us/sample - loss: 6.3665e-13\n",
            "Epoch 321/500\n",
            "30/30 [==============================] - 0s 283us/sample - loss: 6.3665e-13\n",
            "Epoch 322/500\n",
            "30/30 [==============================] - 0s 238us/sample - loss: 6.3665e-13\n",
            "Epoch 323/500\n",
            "30/30 [==============================] - 0s 177us/sample - loss: 6.3665e-13\n",
            "Epoch 324/500\n",
            "30/30 [==============================] - 0s 167us/sample - loss: 6.3665e-13\n",
            "Epoch 325/500\n",
            "30/30 [==============================] - 0s 138us/sample - loss: 6.3665e-13\n",
            "Epoch 326/500\n",
            "30/30 [==============================] - 0s 163us/sample - loss: 6.3665e-13\n",
            "Epoch 327/500\n",
            "30/30 [==============================] - 0s 154us/sample - loss: 6.3665e-13\n",
            "Epoch 328/500\n",
            "30/30 [==============================] - 0s 190us/sample - loss: 6.3665e-13\n",
            "Epoch 329/500\n",
            "30/30 [==============================] - 0s 200us/sample - loss: 6.3665e-13\n",
            "Epoch 330/500\n",
            "30/30 [==============================] - 0s 151us/sample - loss: 6.3665e-13\n",
            "Epoch 331/500\n",
            "30/30 [==============================] - 0s 131us/sample - loss: 6.3665e-13\n",
            "Epoch 332/500\n",
            "30/30 [==============================] - 0s 227us/sample - loss: 6.3665e-13\n",
            "Epoch 333/500\n",
            "30/30 [==============================] - 0s 139us/sample - loss: 6.3665e-13\n",
            "Epoch 334/500\n",
            "30/30 [==============================] - 0s 183us/sample - loss: 6.3665e-13\n",
            "Epoch 335/500\n",
            "30/30 [==============================] - 0s 251us/sample - loss: 6.3665e-13\n",
            "Epoch 336/500\n",
            "30/30 [==============================] - 0s 272us/sample - loss: 6.3665e-13\n",
            "Epoch 337/500\n",
            "30/30 [==============================] - 0s 249us/sample - loss: 6.3665e-13\n",
            "Epoch 338/500\n",
            "30/30 [==============================] - 0s 223us/sample - loss: 6.3665e-13\n",
            "Epoch 339/500\n",
            "30/30 [==============================] - 0s 129us/sample - loss: 6.3665e-13\n",
            "Epoch 340/500\n",
            "30/30 [==============================] - 0s 172us/sample - loss: 6.3665e-13\n",
            "Epoch 341/500\n",
            "30/30 [==============================] - 0s 277us/sample - loss: 6.3665e-13\n",
            "Epoch 342/500\n",
            "30/30 [==============================] - 0s 121us/sample - loss: 6.3665e-13\n",
            "Epoch 343/500\n",
            "30/30 [==============================] - 0s 175us/sample - loss: 6.3665e-13\n",
            "Epoch 344/500\n",
            "30/30 [==============================] - 0s 127us/sample - loss: 6.3665e-13\n",
            "Epoch 345/500\n",
            "30/30 [==============================] - 0s 132us/sample - loss: 6.3665e-13\n",
            "Epoch 346/500\n",
            "30/30 [==============================] - 0s 207us/sample - loss: 6.3665e-13\n",
            "Epoch 347/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 6.3665e-13\n",
            "Epoch 348/500\n",
            "30/30 [==============================] - 0s 262us/sample - loss: 6.3665e-13\n",
            "Epoch 349/500\n",
            "30/30 [==============================] - 0s 164us/sample - loss: 6.3665e-13\n",
            "Epoch 350/500\n",
            "30/30 [==============================] - 0s 213us/sample - loss: 6.3665e-13\n",
            "Epoch 351/500\n",
            "30/30 [==============================] - 0s 217us/sample - loss: 6.3665e-13\n",
            "Epoch 352/500\n",
            "30/30 [==============================] - 0s 241us/sample - loss: 6.3665e-13\n",
            "Epoch 353/500\n",
            "30/30 [==============================] - 0s 263us/sample - loss: 6.3665e-13\n",
            "Epoch 354/500\n",
            "30/30 [==============================] - 0s 220us/sample - loss: 6.3665e-13\n",
            "Epoch 355/500\n",
            "30/30 [==============================] - 0s 225us/sample - loss: 6.3665e-13\n",
            "Epoch 356/500\n",
            "30/30 [==============================] - 0s 186us/sample - loss: 6.3665e-13\n",
            "Epoch 357/500\n",
            "30/30 [==============================] - 0s 243us/sample - loss: 6.3665e-13\n",
            "Epoch 358/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 6.3665e-13\n",
            "Epoch 359/500\n",
            "30/30 [==============================] - 0s 188us/sample - loss: 6.3665e-13\n",
            "Epoch 360/500\n",
            "30/30 [==============================] - 0s 231us/sample - loss: 6.3665e-13\n",
            "Epoch 361/500\n",
            "30/30 [==============================] - 0s 190us/sample - loss: 6.3665e-13\n",
            "Epoch 362/500\n",
            "30/30 [==============================] - 0s 274us/sample - loss: 6.3665e-13\n",
            "Epoch 363/500\n",
            "30/30 [==============================] - 0s 170us/sample - loss: 6.3665e-13\n",
            "Epoch 364/500\n",
            "30/30 [==============================] - 0s 193us/sample - loss: 6.3665e-13\n",
            "Epoch 365/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 6.3665e-13\n",
            "Epoch 366/500\n",
            "30/30 [==============================] - 0s 127us/sample - loss: 6.3665e-13\n",
            "Epoch 367/500\n",
            "30/30 [==============================] - 0s 136us/sample - loss: 6.3665e-13\n",
            "Epoch 368/500\n",
            "30/30 [==============================] - 0s 245us/sample - loss: 6.3665e-13\n",
            "Epoch 369/500\n",
            "30/30 [==============================] - 0s 106us/sample - loss: 6.3665e-13\n",
            "Epoch 370/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 6.3665e-13\n",
            "Epoch 371/500\n",
            "30/30 [==============================] - 0s 128us/sample - loss: 6.3665e-13\n",
            "Epoch 372/500\n",
            "30/30 [==============================] - 0s 171us/sample - loss: 6.3665e-13\n",
            "Epoch 373/500\n",
            "30/30 [==============================] - 0s 275us/sample - loss: 6.3665e-13\n",
            "Epoch 374/500\n",
            "30/30 [==============================] - 0s 299us/sample - loss: 6.3665e-13\n",
            "Epoch 375/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 6.3665e-13\n",
            "Epoch 376/500\n",
            "30/30 [==============================] - 0s 183us/sample - loss: 6.3665e-13\n",
            "Epoch 377/500\n",
            "30/30 [==============================] - 0s 192us/sample - loss: 6.3665e-13\n",
            "Epoch 378/500\n",
            "30/30 [==============================] - 0s 195us/sample - loss: 6.3665e-13\n",
            "Epoch 379/500\n",
            "30/30 [==============================] - 0s 195us/sample - loss: 6.3665e-13\n",
            "Epoch 380/500\n",
            "30/30 [==============================] - 0s 227us/sample - loss: 6.3665e-13\n",
            "Epoch 381/500\n",
            "30/30 [==============================] - 0s 213us/sample - loss: 6.3665e-13\n",
            "Epoch 382/500\n",
            "30/30 [==============================] - 0s 217us/sample - loss: 6.3665e-13\n",
            "Epoch 383/500\n",
            "30/30 [==============================] - 0s 180us/sample - loss: 6.3665e-13\n",
            "Epoch 384/500\n",
            "30/30 [==============================] - 0s 174us/sample - loss: 6.3665e-13\n",
            "Epoch 385/500\n",
            "30/30 [==============================] - 0s 160us/sample - loss: 6.3665e-13\n",
            "Epoch 386/500\n",
            "30/30 [==============================] - 0s 195us/sample - loss: 6.3665e-13\n",
            "Epoch 387/500\n",
            "30/30 [==============================] - 0s 228us/sample - loss: 6.3665e-13\n",
            "Epoch 388/500\n",
            "30/30 [==============================] - 0s 275us/sample - loss: 6.3665e-13\n",
            "Epoch 389/500\n",
            "30/30 [==============================] - 0s 185us/sample - loss: 6.3665e-13\n",
            "Epoch 390/500\n",
            "30/30 [==============================] - 0s 183us/sample - loss: 6.3665e-13\n",
            "Epoch 391/500\n",
            "30/30 [==============================] - 0s 198us/sample - loss: 6.3665e-13\n",
            "Epoch 392/500\n",
            "30/30 [==============================] - 0s 220us/sample - loss: 6.3665e-13\n",
            "Epoch 393/500\n",
            "30/30 [==============================] - 0s 435us/sample - loss: 6.3665e-13\n",
            "Epoch 394/500\n",
            "30/30 [==============================] - 0s 175us/sample - loss: 6.3665e-13\n",
            "Epoch 395/500\n",
            "30/30 [==============================] - 0s 226us/sample - loss: 6.3665e-13\n",
            "Epoch 396/500\n",
            "30/30 [==============================] - 0s 220us/sample - loss: 6.3665e-13\n",
            "Epoch 397/500\n",
            "30/30 [==============================] - 0s 203us/sample - loss: 6.3665e-13\n",
            "Epoch 398/500\n",
            "30/30 [==============================] - 0s 353us/sample - loss: 6.3665e-13\n",
            "Epoch 399/500\n",
            "30/30 [==============================] - 0s 271us/sample - loss: 6.3665e-13\n",
            "Epoch 400/500\n",
            "30/30 [==============================] - 0s 332us/sample - loss: 6.3665e-13\n",
            "Epoch 401/500\n",
            "30/30 [==============================] - 0s 191us/sample - loss: 6.3665e-13\n",
            "Epoch 402/500\n",
            "30/30 [==============================] - 0s 129us/sample - loss: 6.3665e-13\n",
            "Epoch 403/500\n",
            "30/30 [==============================] - 0s 110us/sample - loss: 6.3665e-13\n",
            "Epoch 404/500\n",
            "30/30 [==============================] - 0s 217us/sample - loss: 6.3665e-13\n",
            "Epoch 405/500\n",
            "30/30 [==============================] - 0s 253us/sample - loss: 6.3665e-13\n",
            "Epoch 406/500\n",
            "30/30 [==============================] - 0s 284us/sample - loss: 6.3665e-13\n",
            "Epoch 407/500\n",
            "30/30 [==============================] - 0s 242us/sample - loss: 6.3665e-13\n",
            "Epoch 408/500\n",
            "30/30 [==============================] - 0s 203us/sample - loss: 6.3665e-13\n",
            "Epoch 409/500\n",
            "30/30 [==============================] - 0s 214us/sample - loss: 6.3665e-13\n",
            "Epoch 410/500\n",
            "30/30 [==============================] - 0s 173us/sample - loss: 6.3665e-13\n",
            "Epoch 411/500\n",
            "30/30 [==============================] - 0s 401us/sample - loss: 6.3665e-13\n",
            "Epoch 412/500\n",
            "30/30 [==============================] - 0s 146us/sample - loss: 6.3665e-13\n",
            "Epoch 413/500\n",
            "30/30 [==============================] - 0s 118us/sample - loss: 6.3665e-13\n",
            "Epoch 414/500\n",
            "30/30 [==============================] - 0s 123us/sample - loss: 6.3665e-13\n",
            "Epoch 415/500\n",
            "30/30 [==============================] - 0s 159us/sample - loss: 6.3665e-13\n",
            "Epoch 416/500\n",
            "30/30 [==============================] - 0s 207us/sample - loss: 6.3665e-13\n",
            "Epoch 417/500\n",
            "30/30 [==============================] - 0s 206us/sample - loss: 6.3665e-13\n",
            "Epoch 418/500\n",
            "30/30 [==============================] - 0s 260us/sample - loss: 6.3665e-13\n",
            "Epoch 419/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 6.3665e-13\n",
            "Epoch 420/500\n",
            "30/30 [==============================] - 0s 225us/sample - loss: 6.3665e-13\n",
            "Epoch 421/500\n",
            "30/30 [==============================] - 0s 242us/sample - loss: 6.3665e-13\n",
            "Epoch 422/500\n",
            "30/30 [==============================] - 0s 155us/sample - loss: 6.3665e-13\n",
            "Epoch 423/500\n",
            "30/30 [==============================] - 0s 246us/sample - loss: 6.3665e-13\n",
            "Epoch 424/500\n",
            "30/30 [==============================] - 0s 251us/sample - loss: 6.3665e-13\n",
            "Epoch 425/500\n",
            "30/30 [==============================] - 0s 120us/sample - loss: 6.3665e-13\n",
            "Epoch 426/500\n",
            "30/30 [==============================] - 0s 133us/sample - loss: 6.3665e-13\n",
            "Epoch 427/500\n",
            "30/30 [==============================] - 0s 225us/sample - loss: 6.3665e-13\n",
            "Epoch 428/500\n",
            "30/30 [==============================] - 0s 258us/sample - loss: 6.3665e-13\n",
            "Epoch 429/500\n",
            "30/30 [==============================] - 0s 241us/sample - loss: 6.3665e-13\n",
            "Epoch 430/500\n",
            "30/30 [==============================] - 0s 237us/sample - loss: 6.3665e-13\n",
            "Epoch 431/500\n",
            "30/30 [==============================] - 0s 234us/sample - loss: 6.3665e-13\n",
            "Epoch 432/500\n",
            "30/30 [==============================] - 0s 198us/sample - loss: 6.3665e-13\n",
            "Epoch 433/500\n",
            "30/30 [==============================] - 0s 420us/sample - loss: 6.3665e-13\n",
            "Epoch 434/500\n",
            "30/30 [==============================] - 0s 200us/sample - loss: 6.3665e-13\n",
            "Epoch 435/500\n",
            "30/30 [==============================] - 0s 199us/sample - loss: 6.3665e-13\n",
            "Epoch 436/500\n",
            "30/30 [==============================] - 0s 193us/sample - loss: 6.3665e-13\n",
            "Epoch 437/500\n",
            "30/30 [==============================] - 0s 237us/sample - loss: 6.3665e-13\n",
            "Epoch 438/500\n",
            "30/30 [==============================] - 0s 182us/sample - loss: 6.3665e-13\n",
            "Epoch 439/500\n",
            "30/30 [==============================] - 0s 200us/sample - loss: 6.3665e-13\n",
            "Epoch 440/500\n",
            "30/30 [==============================] - 0s 191us/sample - loss: 6.3665e-13\n",
            "Epoch 441/500\n",
            "30/30 [==============================] - 0s 232us/sample - loss: 6.3665e-13\n",
            "Epoch 442/500\n",
            "30/30 [==============================] - 0s 195us/sample - loss: 6.3665e-13\n",
            "Epoch 443/500\n",
            "30/30 [==============================] - 0s 198us/sample - loss: 6.3665e-13\n",
            "Epoch 444/500\n",
            "30/30 [==============================] - 0s 173us/sample - loss: 6.3665e-13\n",
            "Epoch 445/500\n",
            "30/30 [==============================] - 0s 189us/sample - loss: 6.3665e-13\n",
            "Epoch 446/500\n",
            "30/30 [==============================] - 0s 187us/sample - loss: 6.3665e-13\n",
            "Epoch 447/500\n",
            "30/30 [==============================] - 0s 229us/sample - loss: 6.3665e-13\n",
            "Epoch 448/500\n",
            "30/30 [==============================] - 0s 218us/sample - loss: 6.3665e-13\n",
            "Epoch 449/500\n",
            "30/30 [==============================] - 0s 200us/sample - loss: 6.3665e-13\n",
            "Epoch 450/500\n",
            "30/30 [==============================] - 0s 203us/sample - loss: 6.3665e-13\n",
            "Epoch 451/500\n",
            "30/30 [==============================] - 0s 238us/sample - loss: 6.3665e-13\n",
            "Epoch 452/500\n",
            "30/30 [==============================] - 0s 246us/sample - loss: 6.3665e-13\n",
            "Epoch 453/500\n",
            "30/30 [==============================] - 0s 240us/sample - loss: 6.3665e-13\n",
            "Epoch 454/500\n",
            "30/30 [==============================] - 0s 242us/sample - loss: 6.3665e-13\n",
            "Epoch 455/500\n",
            "30/30 [==============================] - 0s 234us/sample - loss: 6.3665e-13\n",
            "Epoch 456/500\n",
            "30/30 [==============================] - 0s 238us/sample - loss: 6.3665e-13\n",
            "Epoch 457/500\n",
            "30/30 [==============================] - 0s 191us/sample - loss: 6.3665e-13\n",
            "Epoch 458/500\n",
            "30/30 [==============================] - 0s 238us/sample - loss: 6.3665e-13\n",
            "Epoch 459/500\n",
            "30/30 [==============================] - 0s 223us/sample - loss: 6.3665e-13\n",
            "Epoch 460/500\n",
            "30/30 [==============================] - 0s 218us/sample - loss: 6.3665e-13\n",
            "Epoch 461/500\n",
            "30/30 [==============================] - 0s 184us/sample - loss: 6.3665e-13\n",
            "Epoch 462/500\n",
            "30/30 [==============================] - 0s 230us/sample - loss: 6.3665e-13\n",
            "Epoch 463/500\n",
            "30/30 [==============================] - 0s 206us/sample - loss: 6.3665e-13\n",
            "Epoch 464/500\n",
            "30/30 [==============================] - 0s 257us/sample - loss: 6.3665e-13\n",
            "Epoch 465/500\n",
            "30/30 [==============================] - 0s 223us/sample - loss: 6.3665e-13\n",
            "Epoch 466/500\n",
            "30/30 [==============================] - 0s 234us/sample - loss: 6.3665e-13\n",
            "Epoch 467/500\n",
            "30/30 [==============================] - 0s 215us/sample - loss: 6.3665e-13\n",
            "Epoch 468/500\n",
            "30/30 [==============================] - 0s 206us/sample - loss: 6.3665e-13\n",
            "Epoch 469/500\n",
            "30/30 [==============================] - 0s 211us/sample - loss: 6.3665e-13\n",
            "Epoch 470/500\n",
            "30/30 [==============================] - 0s 198us/sample - loss: 6.3665e-13\n",
            "Epoch 471/500\n",
            "30/30 [==============================] - 0s 225us/sample - loss: 6.3665e-13\n",
            "Epoch 472/500\n",
            "30/30 [==============================] - 0s 218us/sample - loss: 6.3665e-13\n",
            "Epoch 473/500\n",
            "30/30 [==============================] - 0s 491us/sample - loss: 6.3665e-13\n",
            "Epoch 474/500\n",
            "30/30 [==============================] - 0s 323us/sample - loss: 6.3665e-13\n",
            "Epoch 475/500\n",
            "30/30 [==============================] - 0s 312us/sample - loss: 6.3665e-13\n",
            "Epoch 476/500\n",
            "30/30 [==============================] - 0s 336us/sample - loss: 6.3665e-13\n",
            "Epoch 477/500\n",
            "30/30 [==============================] - 0s 250us/sample - loss: 6.3665e-13\n",
            "Epoch 478/500\n",
            "30/30 [==============================] - 0s 268us/sample - loss: 6.3665e-13\n",
            "Epoch 479/500\n",
            "30/30 [==============================] - 0s 207us/sample - loss: 6.3665e-13\n",
            "Epoch 480/500\n",
            "30/30 [==============================] - 0s 235us/sample - loss: 6.3665e-13\n",
            "Epoch 481/500\n",
            "30/30 [==============================] - 0s 206us/sample - loss: 6.3665e-13\n",
            "Epoch 482/500\n",
            "30/30 [==============================] - 0s 204us/sample - loss: 6.3665e-13\n",
            "Epoch 483/500\n",
            "30/30 [==============================] - 0s 305us/sample - loss: 6.3665e-13\n",
            "Epoch 484/500\n",
            "30/30 [==============================] - 0s 296us/sample - loss: 6.3665e-13\n",
            "Epoch 485/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 6.3665e-13\n",
            "Epoch 486/500\n",
            "30/30 [==============================] - 0s 165us/sample - loss: 6.3665e-13\n",
            "Epoch 487/500\n",
            "30/30 [==============================] - 0s 184us/sample - loss: 6.3665e-13\n",
            "Epoch 488/500\n",
            "30/30 [==============================] - 0s 184us/sample - loss: 6.3665e-13\n",
            "Epoch 489/500\n",
            "30/30 [==============================] - 0s 227us/sample - loss: 6.3665e-13\n",
            "Epoch 490/500\n",
            "30/30 [==============================] - 0s 208us/sample - loss: 6.3665e-13\n",
            "Epoch 491/500\n",
            "30/30 [==============================] - 0s 158us/sample - loss: 6.3665e-13\n",
            "Epoch 492/500\n",
            "30/30 [==============================] - 0s 308us/sample - loss: 6.3665e-13\n",
            "Epoch 493/500\n",
            "30/30 [==============================] - 0s 319us/sample - loss: 6.3665e-13\n",
            "Epoch 494/500\n",
            "30/30 [==============================] - 0s 214us/sample - loss: 6.3665e-13\n",
            "Epoch 495/500\n",
            "30/30 [==============================] - 0s 220us/sample - loss: 6.3665e-13\n",
            "Epoch 496/500\n",
            "30/30 [==============================] - 0s 245us/sample - loss: 6.3665e-13\n",
            "Epoch 497/500\n",
            "30/30 [==============================] - 0s 287us/sample - loss: 6.3665e-13\n",
            "Epoch 498/500\n",
            "30/30 [==============================] - 0s 190us/sample - loss: 6.3665e-13\n",
            "Epoch 499/500\n",
            "30/30 [==============================] - 0s 312us/sample - loss: 6.3665e-13\n",
            "Epoch 500/500\n",
            "30/30 [==============================] - 0s 258us/sample - loss: 6.3665e-13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7yUm8IwDupB",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHYR_XzsBXLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cb4c8b2-1fca-493b-b4b0-10bf8817e727"
      },
      "source": [
        "epochs_hist.history.keys()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYuOlYhNESUr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "00c577ad-f045-4bd9-c348-f33bfc61af6b"
      },
      "source": [
        "epochs_hist.history['loss'][1:10]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[989.6683349609375,\n",
              " 1051.5029296875,\n",
              " 938.5480346679688,\n",
              " 825.9215698242188,\n",
              " 803.1168212890625,\n",
              " 800.5527954101562,\n",
              " 746.5761108398438,\n",
              " 667.4160766601562,\n",
              " 613.689697265625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8x66F3bD30z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "f066ecaf-d868-4ac1-9911-395ac5361ac1"
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs_hist.history['loss'])\n",
        "plt.title('Model Loss Progress During Training')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAGDCAYAAACbcTyoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ-FtgGWEM-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73e71715-8204-4361-e8fd-6129b3b76da8"
      },
      "source": [
        "# what are the weights which the model has determined to be the best?\n",
        "\n",
        "model.get_weights()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[1.8000001]], dtype=float32), array([32.], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzQjceFzFitH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# That is exactly what is in the conversion formula: T(f) = T(C) *9/5 + 32\n",
        "# 9/5 is 1.8 and bias 32\n",
        "# So, instead of defining the formula in advance (as in traditional programming),\n",
        "# we fed data with known inputs and outputs and the machine determined the formula."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0byed0gIGyLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9da7117e-02ae-4324-f5d2-28e394ebcafd"
      },
      "source": [
        "TempC = [-35, -20, 0, 10, 20, 30]\n",
        "\n",
        "print('Temperature conversion using trained ANN')\n",
        "print('='*40)\n",
        "for tempC in TempC:\n",
        "  tempF = model.predict([tempC])\n",
        "  print('Temp {} in DegC = temp {} in degF'.format(tempC, tempF))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature conversion using trained ANN\n",
            "========================================\n",
            "Temp -35 in DegC = temp [[-31.000004]] in degF\n",
            "Temp -20 in DegC = temp [[-4.]] in degF\n",
            "Temp 0 in DegC = temp [[32.]] in degF\n",
            "Temp 10 in DegC = temp [[50.]] in degF\n",
            "Temp 20 in DegC = temp [[68.]] in degF\n",
            "Temp 30 in DegC = temp [[86.]] in degF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkOXJTBOHHKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}