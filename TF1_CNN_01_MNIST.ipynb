{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF1_CNN_01_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noircir/TensorFlow-Examples/blob/master/TF1_CNN_01_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUt5y-TBfs3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeSv2N4tf4lC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YaU8congC2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O51fPOJ-geaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inK32sHLf-fr",
        "colab_type": "code",
        "outputId": "faaf11fe-86df-453a-98a5-e79171e8dc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "mnist = input_data.read_data_sets('/content/drive/My Drive/Colab Notebooks/TF 1.0/MNIST_data2/',one_hot=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-7239965444e6>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /content/drive/My Drive/Colab Notebooks/TF 1.0/MNIST_data2/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /content/drive/My Drive/Colab Notebooks/TF 1.0/MNIST_data2/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting /content/drive/My Drive/Colab Notebooks/TF 1.0/MNIST_data2/t10k-images-idx3-ubyte.gz\n",
            "Extracting /content/drive/My Drive/Colab Notebooks/TF 1.0/MNIST_data2/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c9p--ofmFI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# difference between truncated normal and normal distributions\n",
        "# https://bit.ly/2rukskm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 500000\n",
        "A = tf.truncated_normal(shape=(n,)) # shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
        "B = tf.random_normal(shape=(n,))\n",
        "with tf.Session() as sess:\n",
        "    a, b = sess.run([A, B])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB2PxOQImMWz",
        "colab_type": "code",
        "outputId": "35dbff7d-5358-4b79-facf-4156baca0dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist(a, bins=100, range=(-4.2, 4.2), color='orange', alpha=0.5);\n",
        "plt.hist(b, bins=100, range=(-4.2, 4.2), color='green', alpha=0.3);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRaAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhDUfQfyg31S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HELPER\n",
        "\n",
        "# INIT WEIGHTS\n",
        "# the shape of weights depends on the shape of tensor\n",
        "\n",
        "def init_weights(shape):\n",
        "  init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
        "  return tf.Variable(init_random_dist)\n",
        "\n",
        "# INIT BIAS\n",
        "# the shape of biases depends on the shape of tensor\n",
        "\n",
        "def init_bias(shape):\n",
        "  init_bias_vals = tf.constant(value=0.1, shape=shape)\n",
        "  return tf.Variable(init_bias_vals)\n",
        "\n",
        "# CONV2D\n",
        "\n",
        "def conv2d(x,W):\n",
        "  # x --> [batch, H, W, Channels]\n",
        "  # W --> [filter H, filter W, Channels IN, Channels OUT]\n",
        "\n",
        "  return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME') # 'SAME\" means padding of zeros\n",
        "\n",
        "# POOLING\n",
        "# Pooling the max digit that the filter calculates (sharpening or blurring)\n",
        "\n",
        "def max_pool_2by2(x):\n",
        "  # x --> [batch,h,w,c]\n",
        "  # we are only concerned with individual images height and width: 2x2\n",
        "  return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iPL0qMHCbDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CONVOLUTIONAL LAYER\n",
        "\n",
        "def convolutional_layer(input_x, shape):\n",
        "  W = init_weights(shape)\n",
        "  b = init_bias([shape[3]])\n",
        "  # ReLu is applied to the result of convolution\n",
        "  return tf.nn.relu(conv2d(input_x, W)+b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaU8U-PbN5xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NORMAL FULLY CONNECTED LAYER\n",
        "\n",
        "def normal_full_layer(input_layer, size):\n",
        "  input_size = int(input_layer.get_shape()[1])\n",
        "  W = init_weights([input_size, size])\n",
        "  b = init_bias([size])\n",
        "  return tf.matmul(input_layer,W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwCkGMRiOqHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PLACEHOLDERS\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=[None,784])\n",
        "y_true = tf.placeholder(tf.float32,shape=[None,10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjgUoqyjSUwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LAYERS\n",
        "\n",
        "x_image = tf.reshape(x, [-1,28,28,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3JP9Xi1MhfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# computing 32 features for each 5x5 patch, 1 is the number of channels, 32 is the number of features we are computing\n",
        "convo_1 = convolutional_layer(x_image, shape=[5,5,1,32])\n",
        "convo_1_pooling = max_pool_2by2(convo_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQwMfQzeKT4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convo_2 = convolutional_layer(convo_1_pooling, shape = [5,5,32,64])\n",
        "convo_2_pooling = max_pool_2by2(convo_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq-WHPLVME36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Why 7 by 7 image? Because we did 2 pooling layers, so (28/2)/2 = 7\n",
        "# 64 then just comes from the output of the previous Convolution\n",
        "convo_2_flat = tf.reshape(convo_2_pooling, [-1,7*7*64])\n",
        "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1024))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgB7Q4k8MGaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DROPOUT\n",
        "\n",
        "# NOTE THE PLACEHOLDER HERE!\n",
        "hold_prob = tf.placeholder(tf.float32)\n",
        "full_one_dropout = tf.nn.dropout(full_layer_one,rate=1-hold_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmNiW_oZNO3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = normal_full_layer(full_one_dropout,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FkkVfA1S1-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOSS FUNCTION\n",
        "\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB3Vc5uPTOHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OPTIMIZER\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
        "train = optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ulQGCgVTjex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INITIALIZE VARIABLES\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuWm4zoaTre_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38ea0a4d-0b6c-4c00-eb8d-8703294f522a"
      },
      "source": [
        "steps = 5000\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(steps):\n",
        "        \n",
        "        batch_x , batch_y = mnist.train.next_batch(50)\n",
        "        \n",
        "        # hold_prob:0.5 means each neuron has 50% chance of being held (randomly)\n",
        "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5}) \n",
        "        \n",
        "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
        "        if i%100 == 0:\n",
        "            \n",
        "            print('Currently on step {}'.format(i))\n",
        "            print('Accuracy is:')\n",
        "\n",
        "            # Test the Train Model\n",
        "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1)) # list of booleans, so we need to cast into float32\n",
        "\n",
        "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "\n",
        "            print(sess.run(acc,feed_dict={x:mnist.test.images,y_true:mnist.test.labels,hold_prob:1.0}))\n",
        "            print('\\n')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently on step 0\n",
            "Accuracy is:\n",
            "0.1509\n",
            "\n",
            "\n",
            "Currently on step 100\n",
            "Accuracy is:\n",
            "0.8402\n",
            "\n",
            "\n",
            "Currently on step 200\n",
            "Accuracy is:\n",
            "0.9052\n",
            "\n",
            "\n",
            "Currently on step 300\n",
            "Accuracy is:\n",
            "0.9209\n",
            "\n",
            "\n",
            "Currently on step 400\n",
            "Accuracy is:\n",
            "0.9386\n",
            "\n",
            "\n",
            "Currently on step 500\n",
            "Accuracy is:\n",
            "0.9464\n",
            "\n",
            "\n",
            "Currently on step 600\n",
            "Accuracy is:\n",
            "0.9503\n",
            "\n",
            "\n",
            "Currently on step 700\n",
            "Accuracy is:\n",
            "0.9564\n",
            "\n",
            "\n",
            "Currently on step 800\n",
            "Accuracy is:\n",
            "0.96\n",
            "\n",
            "\n",
            "Currently on step 900\n",
            "Accuracy is:\n",
            "0.9627\n",
            "\n",
            "\n",
            "Currently on step 1000\n",
            "Accuracy is:\n",
            "0.9651\n",
            "\n",
            "\n",
            "Currently on step 1100\n",
            "Accuracy is:\n",
            "0.9673\n",
            "\n",
            "\n",
            "Currently on step 1200\n",
            "Accuracy is:\n",
            "0.9675\n",
            "\n",
            "\n",
            "Currently on step 1300\n",
            "Accuracy is:\n",
            "0.9686\n",
            "\n",
            "\n",
            "Currently on step 1400\n",
            "Accuracy is:\n",
            "0.969\n",
            "\n",
            "\n",
            "Currently on step 1500\n",
            "Accuracy is:\n",
            "0.9716\n",
            "\n",
            "\n",
            "Currently on step 1600\n",
            "Accuracy is:\n",
            "0.9727\n",
            "\n",
            "\n",
            "Currently on step 1700\n",
            "Accuracy is:\n",
            "0.9745\n",
            "\n",
            "\n",
            "Currently on step 1800\n",
            "Accuracy is:\n",
            "0.9757\n",
            "\n",
            "\n",
            "Currently on step 1900\n",
            "Accuracy is:\n",
            "0.9777\n",
            "\n",
            "\n",
            "Currently on step 2000\n",
            "Accuracy is:\n",
            "0.977\n",
            "\n",
            "\n",
            "Currently on step 2100\n",
            "Accuracy is:\n",
            "0.9785\n",
            "\n",
            "\n",
            "Currently on step 2200\n",
            "Accuracy is:\n",
            "0.9784\n",
            "\n",
            "\n",
            "Currently on step 2300\n",
            "Accuracy is:\n",
            "0.9813\n",
            "\n",
            "\n",
            "Currently on step 2400\n",
            "Accuracy is:\n",
            "0.9787\n",
            "\n",
            "\n",
            "Currently on step 2500\n",
            "Accuracy is:\n",
            "0.9794\n",
            "\n",
            "\n",
            "Currently on step 2600\n",
            "Accuracy is:\n",
            "0.9812\n",
            "\n",
            "\n",
            "Currently on step 2700\n",
            "Accuracy is:\n",
            "0.9812\n",
            "\n",
            "\n",
            "Currently on step 2800\n",
            "Accuracy is:\n",
            "0.9825\n",
            "\n",
            "\n",
            "Currently on step 2900\n",
            "Accuracy is:\n",
            "0.9817\n",
            "\n",
            "\n",
            "Currently on step 3000\n",
            "Accuracy is:\n",
            "0.9817\n",
            "\n",
            "\n",
            "Currently on step 3100\n",
            "Accuracy is:\n",
            "0.983\n",
            "\n",
            "\n",
            "Currently on step 3200\n",
            "Accuracy is:\n",
            "0.9826\n",
            "\n",
            "\n",
            "Currently on step 3300\n",
            "Accuracy is:\n",
            "0.9827\n",
            "\n",
            "\n",
            "Currently on step 3400\n",
            "Accuracy is:\n",
            "0.9846\n",
            "\n",
            "\n",
            "Currently on step 3500\n",
            "Accuracy is:\n",
            "0.9842\n",
            "\n",
            "\n",
            "Currently on step 3600\n",
            "Accuracy is:\n",
            "0.9856\n",
            "\n",
            "\n",
            "Currently on step 3700\n",
            "Accuracy is:\n",
            "0.9853\n",
            "\n",
            "\n",
            "Currently on step 3800\n",
            "Accuracy is:\n",
            "0.9845\n",
            "\n",
            "\n",
            "Currently on step 3900\n",
            "Accuracy is:\n",
            "0.9862\n",
            "\n",
            "\n",
            "Currently on step 4000\n",
            "Accuracy is:\n",
            "0.9857\n",
            "\n",
            "\n",
            "Currently on step 4100\n",
            "Accuracy is:\n",
            "0.9873\n",
            "\n",
            "\n",
            "Currently on step 4200\n",
            "Accuracy is:\n",
            "0.9853\n",
            "\n",
            "\n",
            "Currently on step 4300\n",
            "Accuracy is:\n",
            "0.987\n",
            "\n",
            "\n",
            "Currently on step 4400\n",
            "Accuracy is:\n",
            "0.9852\n",
            "\n",
            "\n",
            "Currently on step 4500\n",
            "Accuracy is:\n",
            "0.9869\n",
            "\n",
            "\n",
            "Currently on step 4600\n",
            "Accuracy is:\n",
            "0.9861\n",
            "\n",
            "\n",
            "Currently on step 4700\n",
            "Accuracy is:\n",
            "0.9851\n",
            "\n",
            "\n",
            "Currently on step 4800\n",
            "Accuracy is:\n",
            "0.9854\n",
            "\n",
            "\n",
            "Currently on step 4900\n",
            "Accuracy is:\n",
            "0.9855\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQda32gNVXrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}